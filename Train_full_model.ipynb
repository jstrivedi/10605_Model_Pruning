{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CNN_pruning_students.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L47XBZWm4T9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22cc2446-51db-46b9-bd96-124612bdcfb9"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "from google.colab import files\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FQTVeAuNiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ffe6e5-45a0-4208-eb76-926bb096edfe"
      },
      "source": [
        "# untar\n",
        "!tar -xvzf dataset.tar.gz\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTzcSoYl4T97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3978044-1274-4ab8-b480-c373f8487e63"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592,933\n",
            "Trainable params: 592,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Nk_MAPqZPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6058cc3-0bdd-41f9-fecd-e1fac21f0c49"
      },
      "source": [
        "# you can use the default hyper-parameters for training, \n",
        "# and val accuracy ~59% after 25 epochs and > 63% after 50 epochs\n",
        "\n",
        "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=300, \n",
        "                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352/352 [==============================] - 5s 12ms/step - loss: 1.0512 - accuracy: 0.5817 - val_loss: 0.9713 - val_accuracy: 0.6182\n",
            "Epoch 2/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.9963 - accuracy: 0.6099 - val_loss: 0.9516 - val_accuracy: 0.6261\n",
            "Epoch 3/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.9434 - accuracy: 0.6312 - val_loss: 1.0165 - val_accuracy: 0.6020\n",
            "Epoch 4/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.9091 - accuracy: 0.6486 - val_loss: 0.9121 - val_accuracy: 0.6420\n",
            "Epoch 5/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8686 - accuracy: 0.6661 - val_loss: 0.9146 - val_accuracy: 0.6440\n",
            "Epoch 6/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.8237 - accuracy: 0.6819 - val_loss: 0.8583 - val_accuracy: 0.6586\n",
            "Epoch 7/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.8035 - accuracy: 0.6937 - val_loss: 0.7957 - val_accuracy: 0.6954\n",
            "Epoch 8/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.7684 - accuracy: 0.7074 - val_loss: 0.8324 - val_accuracy: 0.6816\n",
            "Epoch 9/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.7454 - accuracy: 0.7164 - val_loss: 0.8668 - val_accuracy: 0.6705\n",
            "Epoch 10/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7266 - accuracy: 0.7253 - val_loss: 0.7817 - val_accuracy: 0.7057\n",
            "Epoch 11/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.6990 - accuracy: 0.7345 - val_loss: 0.7774 - val_accuracy: 0.7046\n",
            "Epoch 12/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6811 - accuracy: 0.7430 - val_loss: 0.7587 - val_accuracy: 0.7160\n",
            "Epoch 13/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6585 - accuracy: 0.7525 - val_loss: 0.7529 - val_accuracy: 0.7267\n",
            "Epoch 14/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6415 - accuracy: 0.7583 - val_loss: 0.7413 - val_accuracy: 0.7279\n",
            "Epoch 15/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6211 - accuracy: 0.7665 - val_loss: 0.8244 - val_accuracy: 0.6919\n",
            "Epoch 16/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.6088 - accuracy: 0.7735 - val_loss: 0.7354 - val_accuracy: 0.7311\n",
            "Epoch 17/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.5876 - accuracy: 0.7814 - val_loss: 0.7441 - val_accuracy: 0.7374\n",
            "Epoch 18/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5861 - accuracy: 0.7820 - val_loss: 0.7347 - val_accuracy: 0.7240\n",
            "Epoch 19/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5784 - accuracy: 0.7855 - val_loss: 0.8337 - val_accuracy: 0.6994\n",
            "Epoch 20/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.5623 - accuracy: 0.7908 - val_loss: 0.7121 - val_accuracy: 0.7414\n",
            "Epoch 21/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.5461 - accuracy: 0.7959 - val_loss: 0.7331 - val_accuracy: 0.7358\n",
            "Epoch 22/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5352 - accuracy: 0.8007 - val_loss: 0.7445 - val_accuracy: 0.7287\n",
            "Epoch 23/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5184 - accuracy: 0.8072 - val_loss: 0.7534 - val_accuracy: 0.7497\n",
            "Epoch 24/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.5127 - accuracy: 0.8126 - val_loss: 0.7508 - val_accuracy: 0.7267\n",
            "Epoch 25/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.5067 - accuracy: 0.8110 - val_loss: 0.7188 - val_accuracy: 0.7430\n",
            "Epoch 26/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4956 - accuracy: 0.8158 - val_loss: 0.7314 - val_accuracy: 0.7501\n",
            "Epoch 27/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4970 - accuracy: 0.8182 - val_loss: 0.7519 - val_accuracy: 0.7350\n",
            "Epoch 28/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4869 - accuracy: 0.8230 - val_loss: 0.7728 - val_accuracy: 0.7248\n",
            "Epoch 29/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4724 - accuracy: 0.8235 - val_loss: 0.7365 - val_accuracy: 0.7311\n",
            "Epoch 30/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4704 - accuracy: 0.8255 - val_loss: 0.7482 - val_accuracy: 0.7418\n",
            "Epoch 31/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4485 - accuracy: 0.8380 - val_loss: 0.7647 - val_accuracy: 0.7343\n",
            "Epoch 32/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4481 - accuracy: 0.8343 - val_loss: 0.7778 - val_accuracy: 0.7418\n",
            "Epoch 33/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4417 - accuracy: 0.8413 - val_loss: 0.7770 - val_accuracy: 0.7374\n",
            "Epoch 34/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4393 - accuracy: 0.8395 - val_loss: 0.7643 - val_accuracy: 0.7450\n",
            "Epoch 35/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4354 - accuracy: 0.8396 - val_loss: 0.7683 - val_accuracy: 0.7398\n",
            "Epoch 36/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4193 - accuracy: 0.8468 - val_loss: 0.7544 - val_accuracy: 0.7497\n",
            "Epoch 37/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4232 - accuracy: 0.8447 - val_loss: 0.7448 - val_accuracy: 0.7418\n",
            "Epoch 38/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4100 - accuracy: 0.8509 - val_loss: 0.7277 - val_accuracy: 0.7442\n",
            "Epoch 39/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4140 - accuracy: 0.8497 - val_loss: 0.7688 - val_accuracy: 0.7461\n",
            "Epoch 40/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4098 - accuracy: 0.8530 - val_loss: 0.7868 - val_accuracy: 0.7394\n",
            "Epoch 41/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4109 - accuracy: 0.8492 - val_loss: 0.7616 - val_accuracy: 0.7410\n",
            "Epoch 42/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4075 - accuracy: 0.8511 - val_loss: 0.7663 - val_accuracy: 0.7434\n",
            "Epoch 43/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3927 - accuracy: 0.8564 - val_loss: 0.7543 - val_accuracy: 0.7426\n",
            "Epoch 44/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3962 - accuracy: 0.8546 - val_loss: 0.7589 - val_accuracy: 0.7461\n",
            "Epoch 45/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3881 - accuracy: 0.8600 - val_loss: 0.7620 - val_accuracy: 0.7521\n",
            "Epoch 46/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3830 - accuracy: 0.8610 - val_loss: 0.7510 - val_accuracy: 0.7513\n",
            "Epoch 47/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3914 - accuracy: 0.8588 - val_loss: 0.7576 - val_accuracy: 0.7434\n",
            "Epoch 48/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3752 - accuracy: 0.8645 - val_loss: 0.7737 - val_accuracy: 0.7390\n",
            "Epoch 49/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3713 - accuracy: 0.8663 - val_loss: 0.7907 - val_accuracy: 0.7430\n",
            "Epoch 50/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3685 - accuracy: 0.8676 - val_loss: 0.7453 - val_accuracy: 0.7457\n",
            "Epoch 51/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3810 - accuracy: 0.8637 - val_loss: 0.8107 - val_accuracy: 0.7410\n",
            "Epoch 52/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3706 - accuracy: 0.8669 - val_loss: 0.7917 - val_accuracy: 0.7473\n",
            "Epoch 53/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3569 - accuracy: 0.8729 - val_loss: 0.7778 - val_accuracy: 0.7378\n",
            "Epoch 54/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3659 - accuracy: 0.8707 - val_loss: 0.8182 - val_accuracy: 0.7327\n",
            "Epoch 55/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3695 - accuracy: 0.8697 - val_loss: 0.7634 - val_accuracy: 0.7442\n",
            "Epoch 56/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3582 - accuracy: 0.8728 - val_loss: 0.7774 - val_accuracy: 0.7481\n",
            "Epoch 57/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3621 - accuracy: 0.8705 - val_loss: 0.8262 - val_accuracy: 0.7450\n",
            "Epoch 58/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3443 - accuracy: 0.8792 - val_loss: 0.7563 - val_accuracy: 0.7541\n",
            "Epoch 59/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3435 - accuracy: 0.8791 - val_loss: 0.7793 - val_accuracy: 0.7568\n",
            "Epoch 60/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3469 - accuracy: 0.8746 - val_loss: 0.7943 - val_accuracy: 0.7533\n",
            "Epoch 61/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3523 - accuracy: 0.8746 - val_loss: 0.7744 - val_accuracy: 0.7442\n",
            "Epoch 62/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3580 - accuracy: 0.8711 - val_loss: 0.8163 - val_accuracy: 0.7457\n",
            "Epoch 63/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3418 - accuracy: 0.8777 - val_loss: 0.8153 - val_accuracy: 0.7410\n",
            "Epoch 64/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3473 - accuracy: 0.8770 - val_loss: 0.7958 - val_accuracy: 0.7414\n",
            "Epoch 65/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3339 - accuracy: 0.8832 - val_loss: 0.7995 - val_accuracy: 0.7422\n",
            "Epoch 66/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3454 - accuracy: 0.8784 - val_loss: 0.8178 - val_accuracy: 0.7370\n",
            "Epoch 67/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3376 - accuracy: 0.8815 - val_loss: 0.7823 - val_accuracy: 0.7501\n",
            "Epoch 68/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3324 - accuracy: 0.8821 - val_loss: 0.8018 - val_accuracy: 0.7390\n",
            "Epoch 69/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3338 - accuracy: 0.8823 - val_loss: 0.7975 - val_accuracy: 0.7521\n",
            "Epoch 70/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3342 - accuracy: 0.8821 - val_loss: 0.8082 - val_accuracy: 0.7477\n",
            "Epoch 71/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3374 - accuracy: 0.8816 - val_loss: 0.8113 - val_accuracy: 0.7485\n",
            "Epoch 72/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3356 - accuracy: 0.8828 - val_loss: 0.8214 - val_accuracy: 0.7442\n",
            "Epoch 73/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3252 - accuracy: 0.8848 - val_loss: 0.7972 - val_accuracy: 0.7465\n",
            "Epoch 74/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3324 - accuracy: 0.8855 - val_loss: 0.7976 - val_accuracy: 0.7533\n",
            "Epoch 75/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3323 - accuracy: 0.8827 - val_loss: 0.7957 - val_accuracy: 0.7497\n",
            "Epoch 76/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3232 - accuracy: 0.8865 - val_loss: 0.8052 - val_accuracy: 0.7442\n",
            "Epoch 77/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3202 - accuracy: 0.8894 - val_loss: 0.8140 - val_accuracy: 0.7489\n",
            "Epoch 78/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3261 - accuracy: 0.8864 - val_loss: 0.7850 - val_accuracy: 0.7457\n",
            "Epoch 79/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3148 - accuracy: 0.8905 - val_loss: 0.7797 - val_accuracy: 0.7450\n",
            "Epoch 80/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3227 - accuracy: 0.8875 - val_loss: 0.8171 - val_accuracy: 0.7461\n",
            "Epoch 81/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3227 - accuracy: 0.8874 - val_loss: 0.8049 - val_accuracy: 0.7477\n",
            "Epoch 82/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3120 - accuracy: 0.8936 - val_loss: 0.7987 - val_accuracy: 0.7477\n",
            "Epoch 83/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3140 - accuracy: 0.8937 - val_loss: 0.7795 - val_accuracy: 0.7489\n",
            "Epoch 84/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3089 - accuracy: 0.8919 - val_loss: 0.8621 - val_accuracy: 0.7406\n",
            "Epoch 85/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3216 - accuracy: 0.8907 - val_loss: 0.8666 - val_accuracy: 0.7434\n",
            "Epoch 86/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3049 - accuracy: 0.8952 - val_loss: 0.8354 - val_accuracy: 0.7446\n",
            "Epoch 87/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3076 - accuracy: 0.8922 - val_loss: 0.8353 - val_accuracy: 0.7418\n",
            "Epoch 88/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3127 - accuracy: 0.8916 - val_loss: 0.8138 - val_accuracy: 0.7493\n",
            "Epoch 89/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3144 - accuracy: 0.8913 - val_loss: 0.7928 - val_accuracy: 0.7533\n",
            "Epoch 90/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3111 - accuracy: 0.8929 - val_loss: 0.8460 - val_accuracy: 0.7339\n",
            "Epoch 91/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3244 - accuracy: 0.8878 - val_loss: 0.8441 - val_accuracy: 0.7382\n",
            "Epoch 92/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3022 - accuracy: 0.8978 - val_loss: 0.8302 - val_accuracy: 0.7529\n",
            "Epoch 93/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3084 - accuracy: 0.8964 - val_loss: 0.8408 - val_accuracy: 0.7517\n",
            "Epoch 94/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3085 - accuracy: 0.8955 - val_loss: 0.8342 - val_accuracy: 0.7533\n",
            "Epoch 95/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3067 - accuracy: 0.8939 - val_loss: 0.8468 - val_accuracy: 0.7461\n",
            "Epoch 96/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3016 - accuracy: 0.8964 - val_loss: 0.8675 - val_accuracy: 0.7434\n",
            "Epoch 97/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2950 - accuracy: 0.8994 - val_loss: 0.8328 - val_accuracy: 0.7513\n",
            "Epoch 98/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2907 - accuracy: 0.9000 - val_loss: 0.8191 - val_accuracy: 0.7521\n",
            "Epoch 99/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2995 - accuracy: 0.8984 - val_loss: 0.8213 - val_accuracy: 0.7414\n",
            "Epoch 100/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3001 - accuracy: 0.8981 - val_loss: 0.8157 - val_accuracy: 0.7473\n",
            "Epoch 101/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3050 - accuracy: 0.8950 - val_loss: 0.8281 - val_accuracy: 0.7390\n",
            "Epoch 102/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3041 - accuracy: 0.8974 - val_loss: 0.8628 - val_accuracy: 0.7343\n",
            "Epoch 103/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3024 - accuracy: 0.8974 - val_loss: 0.7953 - val_accuracy: 0.7549\n",
            "Epoch 104/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2935 - accuracy: 0.9002 - val_loss: 0.8382 - val_accuracy: 0.7390\n",
            "Epoch 105/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2863 - accuracy: 0.9019 - val_loss: 0.8459 - val_accuracy: 0.7354\n",
            "Epoch 106/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3012 - accuracy: 0.8974 - val_loss: 0.8170 - val_accuracy: 0.7568\n",
            "Epoch 107/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2761 - accuracy: 0.9057 - val_loss: 0.8760 - val_accuracy: 0.7422\n",
            "Epoch 108/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2941 - accuracy: 0.9014 - val_loss: 0.8178 - val_accuracy: 0.7450\n",
            "Epoch 109/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2914 - accuracy: 0.9015 - val_loss: 0.8889 - val_accuracy: 0.7426\n",
            "Epoch 110/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2964 - accuracy: 0.8986 - val_loss: 0.8383 - val_accuracy: 0.7517\n",
            "Epoch 111/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2858 - accuracy: 0.9036 - val_loss: 0.9092 - val_accuracy: 0.7430\n",
            "Epoch 112/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2839 - accuracy: 0.9034 - val_loss: 0.8254 - val_accuracy: 0.7556\n",
            "Epoch 113/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2924 - accuracy: 0.9017 - val_loss: 0.8404 - val_accuracy: 0.7509\n",
            "Epoch 114/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2890 - accuracy: 0.9039 - val_loss: 0.8230 - val_accuracy: 0.7493\n",
            "Epoch 115/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2834 - accuracy: 0.9048 - val_loss: 0.8331 - val_accuracy: 0.7560\n",
            "Epoch 116/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2923 - accuracy: 0.9030 - val_loss: 0.8792 - val_accuracy: 0.7406\n",
            "Epoch 117/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2890 - accuracy: 0.9021 - val_loss: 0.8718 - val_accuracy: 0.7414\n",
            "Epoch 118/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2805 - accuracy: 0.9061 - val_loss: 0.8482 - val_accuracy: 0.7469\n",
            "Epoch 119/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2874 - accuracy: 0.9039 - val_loss: 0.8684 - val_accuracy: 0.7457\n",
            "Epoch 120/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2933 - accuracy: 0.9007 - val_loss: 0.8688 - val_accuracy: 0.7390\n",
            "Epoch 121/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2860 - accuracy: 0.9054 - val_loss: 0.8082 - val_accuracy: 0.7624\n",
            "Epoch 122/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2800 - accuracy: 0.9054 - val_loss: 0.8221 - val_accuracy: 0.7509\n",
            "Epoch 123/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2833 - accuracy: 0.9077 - val_loss: 0.8397 - val_accuracy: 0.7568\n",
            "Epoch 124/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2803 - accuracy: 0.9050 - val_loss: 0.8130 - val_accuracy: 0.7529\n",
            "Epoch 125/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2849 - accuracy: 0.9041 - val_loss: 0.8299 - val_accuracy: 0.7473\n",
            "Epoch 126/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2878 - accuracy: 0.9037 - val_loss: 0.8306 - val_accuracy: 0.7453\n",
            "Epoch 127/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2861 - accuracy: 0.9048 - val_loss: 0.8617 - val_accuracy: 0.7465\n",
            "Epoch 128/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2792 - accuracy: 0.9046 - val_loss: 0.8644 - val_accuracy: 0.7584\n",
            "Epoch 129/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2836 - accuracy: 0.9051 - val_loss: 0.9100 - val_accuracy: 0.7473\n",
            "Epoch 130/300\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2769 - accuracy: 0.9058 - val_loss: 0.8732 - val_accuracy: 0.7541\n",
            "Epoch 131/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2739 - accuracy: 0.9103 - val_loss: 0.8865 - val_accuracy: 0.7450\n",
            "Epoch 132/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2709 - accuracy: 0.9103 - val_loss: 0.8375 - val_accuracy: 0.7533\n",
            "Epoch 133/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2798 - accuracy: 0.9072 - val_loss: 0.8756 - val_accuracy: 0.7382\n",
            "Epoch 134/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2750 - accuracy: 0.9098 - val_loss: 0.8831 - val_accuracy: 0.7485\n",
            "Epoch 135/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2747 - accuracy: 0.9075 - val_loss: 0.8577 - val_accuracy: 0.7545\n",
            "Epoch 136/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2787 - accuracy: 0.9074 - val_loss: 0.8809 - val_accuracy: 0.7469\n",
            "Epoch 137/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2743 - accuracy: 0.9091 - val_loss: 0.8717 - val_accuracy: 0.7556\n",
            "Epoch 138/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2730 - accuracy: 0.9102 - val_loss: 0.8282 - val_accuracy: 0.7513\n",
            "Epoch 139/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2752 - accuracy: 0.9092 - val_loss: 0.9033 - val_accuracy: 0.7485\n",
            "Epoch 140/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2811 - accuracy: 0.9084 - val_loss: 0.8416 - val_accuracy: 0.7438\n",
            "Epoch 141/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2639 - accuracy: 0.9133 - val_loss: 0.8731 - val_accuracy: 0.7651\n",
            "Epoch 142/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2591 - accuracy: 0.9123 - val_loss: 0.9225 - val_accuracy: 0.7406\n",
            "Epoch 143/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2778 - accuracy: 0.9075 - val_loss: 0.8958 - val_accuracy: 0.7568\n",
            "Epoch 144/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2685 - accuracy: 0.9109 - val_loss: 0.8447 - val_accuracy: 0.7612\n",
            "Epoch 145/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2648 - accuracy: 0.9146 - val_loss: 0.9216 - val_accuracy: 0.7485\n",
            "Epoch 146/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2762 - accuracy: 0.9098 - val_loss: 0.8496 - val_accuracy: 0.7584\n",
            "Epoch 147/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2632 - accuracy: 0.9140 - val_loss: 0.8373 - val_accuracy: 0.7549\n",
            "Epoch 148/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2829 - accuracy: 0.9086 - val_loss: 0.8388 - val_accuracy: 0.7541\n",
            "Epoch 149/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2753 - accuracy: 0.9091 - val_loss: 0.8433 - val_accuracy: 0.7552\n",
            "Epoch 150/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2657 - accuracy: 0.9131 - val_loss: 0.8272 - val_accuracy: 0.7537\n",
            "Epoch 151/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2637 - accuracy: 0.9147 - val_loss: 0.8960 - val_accuracy: 0.7446\n",
            "Epoch 152/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2619 - accuracy: 0.9150 - val_loss: 0.8587 - val_accuracy: 0.7517\n",
            "Epoch 153/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2628 - accuracy: 0.9136 - val_loss: 0.8877 - val_accuracy: 0.7564\n",
            "Epoch 154/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2659 - accuracy: 0.9119 - val_loss: 0.8506 - val_accuracy: 0.7485\n",
            "Epoch 155/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2745 - accuracy: 0.9105 - val_loss: 0.8746 - val_accuracy: 0.7564\n",
            "Epoch 156/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2700 - accuracy: 0.9132 - val_loss: 0.8709 - val_accuracy: 0.7489\n",
            "Epoch 157/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2676 - accuracy: 0.9107 - val_loss: 0.8342 - val_accuracy: 0.7568\n",
            "Epoch 158/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2666 - accuracy: 0.9132 - val_loss: 0.9000 - val_accuracy: 0.7461\n",
            "Epoch 159/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2720 - accuracy: 0.9127 - val_loss: 0.8241 - val_accuracy: 0.7616\n",
            "Epoch 160/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2622 - accuracy: 0.9146 - val_loss: 0.8104 - val_accuracy: 0.7588\n",
            "Epoch 161/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2634 - accuracy: 0.9135 - val_loss: 0.8777 - val_accuracy: 0.7493\n",
            "Epoch 162/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2500 - accuracy: 0.9194 - val_loss: 0.8830 - val_accuracy: 0.7497\n",
            "Epoch 163/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2627 - accuracy: 0.9139 - val_loss: 0.8618 - val_accuracy: 0.7576\n",
            "Epoch 164/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2524 - accuracy: 0.9183 - val_loss: 0.8722 - val_accuracy: 0.7501\n",
            "Epoch 165/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2685 - accuracy: 0.9127 - val_loss: 0.8784 - val_accuracy: 0.7450\n",
            "Epoch 166/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2694 - accuracy: 0.9125 - val_loss: 0.8578 - val_accuracy: 0.7537\n",
            "Epoch 167/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2659 - accuracy: 0.9151 - val_loss: 0.8525 - val_accuracy: 0.7580\n",
            "Epoch 168/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2591 - accuracy: 0.9162 - val_loss: 0.8696 - val_accuracy: 0.7533\n",
            "Epoch 169/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2642 - accuracy: 0.9125 - val_loss: 0.8690 - val_accuracy: 0.7465\n",
            "Epoch 170/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2577 - accuracy: 0.9174 - val_loss: 0.8878 - val_accuracy: 0.7489\n",
            "Epoch 171/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2694 - accuracy: 0.9114 - val_loss: 0.8900 - val_accuracy: 0.7509\n",
            "Epoch 172/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2605 - accuracy: 0.9155 - val_loss: 0.8627 - val_accuracy: 0.7552\n",
            "Epoch 173/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2582 - accuracy: 0.9177 - val_loss: 0.8869 - val_accuracy: 0.7552\n",
            "Epoch 174/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2560 - accuracy: 0.9183 - val_loss: 0.8909 - val_accuracy: 0.7537\n",
            "Epoch 175/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2672 - accuracy: 0.9127 - val_loss: 0.8506 - val_accuracy: 0.7556\n",
            "Epoch 176/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2649 - accuracy: 0.9136 - val_loss: 0.8251 - val_accuracy: 0.7572\n",
            "Epoch 177/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2644 - accuracy: 0.9142 - val_loss: 0.8526 - val_accuracy: 0.7568\n",
            "Epoch 178/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2650 - accuracy: 0.9139 - val_loss: 0.8907 - val_accuracy: 0.7473\n",
            "Epoch 179/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2531 - accuracy: 0.9173 - val_loss: 0.8612 - val_accuracy: 0.7580\n",
            "Epoch 180/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2511 - accuracy: 0.9206 - val_loss: 0.8675 - val_accuracy: 0.7560\n",
            "Epoch 181/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2532 - accuracy: 0.9209 - val_loss: 0.9012 - val_accuracy: 0.7438\n",
            "Epoch 182/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2581 - accuracy: 0.9162 - val_loss: 0.9110 - val_accuracy: 0.7347\n",
            "Epoch 183/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2472 - accuracy: 0.9190 - val_loss: 0.8920 - val_accuracy: 0.7438\n",
            "Epoch 184/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2609 - accuracy: 0.9137 - val_loss: 0.8870 - val_accuracy: 0.7552\n",
            "Epoch 185/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2617 - accuracy: 0.9155 - val_loss: 0.8663 - val_accuracy: 0.7485\n",
            "Epoch 186/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2469 - accuracy: 0.9212 - val_loss: 0.9675 - val_accuracy: 0.7378\n",
            "Epoch 187/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2660 - accuracy: 0.9145 - val_loss: 0.8520 - val_accuracy: 0.7568\n",
            "Epoch 188/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2544 - accuracy: 0.9184 - val_loss: 0.8880 - val_accuracy: 0.7552\n",
            "Epoch 189/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2528 - accuracy: 0.9174 - val_loss: 0.9060 - val_accuracy: 0.7461\n",
            "Epoch 190/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2498 - accuracy: 0.9197 - val_loss: 0.8981 - val_accuracy: 0.7497\n",
            "Epoch 191/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2455 - accuracy: 0.9200 - val_loss: 0.9472 - val_accuracy: 0.7319\n",
            "Epoch 192/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2554 - accuracy: 0.9179 - val_loss: 0.9256 - val_accuracy: 0.7327\n",
            "Epoch 193/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2528 - accuracy: 0.9179 - val_loss: 0.8680 - val_accuracy: 0.7422\n",
            "Epoch 194/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2486 - accuracy: 0.9185 - val_loss: 0.8843 - val_accuracy: 0.7505\n",
            "Epoch 195/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2475 - accuracy: 0.9203 - val_loss: 0.9060 - val_accuracy: 0.7457\n",
            "Epoch 196/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2490 - accuracy: 0.9200 - val_loss: 0.9050 - val_accuracy: 0.7442\n",
            "Epoch 197/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2579 - accuracy: 0.9167 - val_loss: 0.9190 - val_accuracy: 0.7477\n",
            "Epoch 198/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2532 - accuracy: 0.9180 - val_loss: 0.8766 - val_accuracy: 0.7453\n",
            "Epoch 199/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2431 - accuracy: 0.9223 - val_loss: 0.8511 - val_accuracy: 0.7525\n",
            "Epoch 200/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2497 - accuracy: 0.9215 - val_loss: 0.9502 - val_accuracy: 0.7398\n",
            "Epoch 201/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2488 - accuracy: 0.9211 - val_loss: 0.8671 - val_accuracy: 0.7517\n",
            "Epoch 202/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2525 - accuracy: 0.9190 - val_loss: 0.8819 - val_accuracy: 0.7564\n",
            "Epoch 203/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2538 - accuracy: 0.9179 - val_loss: 0.8617 - val_accuracy: 0.7541\n",
            "Epoch 204/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2438 - accuracy: 0.9235 - val_loss: 0.9292 - val_accuracy: 0.7402\n",
            "Epoch 205/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2488 - accuracy: 0.9186 - val_loss: 0.8845 - val_accuracy: 0.7517\n",
            "Epoch 206/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2441 - accuracy: 0.9208 - val_loss: 0.8638 - val_accuracy: 0.7564\n",
            "Epoch 207/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2501 - accuracy: 0.9202 - val_loss: 0.8668 - val_accuracy: 0.7683\n",
            "Epoch 208/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2588 - accuracy: 0.9171 - val_loss: 0.9056 - val_accuracy: 0.7509\n",
            "Epoch 209/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2470 - accuracy: 0.9225 - val_loss: 0.8846 - val_accuracy: 0.7505\n",
            "Epoch 210/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2377 - accuracy: 0.9242 - val_loss: 0.8966 - val_accuracy: 0.7501\n",
            "Epoch 211/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2505 - accuracy: 0.9200 - val_loss: 0.8902 - val_accuracy: 0.7541\n",
            "Epoch 212/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2504 - accuracy: 0.9218 - val_loss: 0.9246 - val_accuracy: 0.7497\n",
            "Epoch 213/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2412 - accuracy: 0.9217 - val_loss: 0.9074 - val_accuracy: 0.7671\n",
            "Epoch 214/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2556 - accuracy: 0.9192 - val_loss: 0.8775 - val_accuracy: 0.7537\n",
            "Epoch 215/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2484 - accuracy: 0.9208 - val_loss: 0.8835 - val_accuracy: 0.7505\n",
            "Epoch 216/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2371 - accuracy: 0.9240 - val_loss: 0.9017 - val_accuracy: 0.7505\n",
            "Epoch 217/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2472 - accuracy: 0.9238 - val_loss: 0.9101 - val_accuracy: 0.7497\n",
            "Epoch 218/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2484 - accuracy: 0.9228 - val_loss: 0.8733 - val_accuracy: 0.7513\n",
            "Epoch 219/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2494 - accuracy: 0.9192 - val_loss: 0.8809 - val_accuracy: 0.7513\n",
            "Epoch 220/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2424 - accuracy: 0.9239 - val_loss: 0.9075 - val_accuracy: 0.7446\n",
            "Epoch 221/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2444 - accuracy: 0.9231 - val_loss: 0.8606 - val_accuracy: 0.7584\n",
            "Epoch 222/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2362 - accuracy: 0.9258 - val_loss: 0.8885 - val_accuracy: 0.7628\n",
            "Epoch 223/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2554 - accuracy: 0.9208 - val_loss: 0.9170 - val_accuracy: 0.7509\n",
            "Epoch 224/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2456 - accuracy: 0.9212 - val_loss: 0.9008 - val_accuracy: 0.7497\n",
            "Epoch 225/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2444 - accuracy: 0.9224 - val_loss: 0.8823 - val_accuracy: 0.7418\n",
            "Epoch 226/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2444 - accuracy: 0.9239 - val_loss: 0.8565 - val_accuracy: 0.7588\n",
            "Epoch 227/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2451 - accuracy: 0.9236 - val_loss: 0.9079 - val_accuracy: 0.7434\n",
            "Epoch 228/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2517 - accuracy: 0.9200 - val_loss: 0.8739 - val_accuracy: 0.7497\n",
            "Epoch 229/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2432 - accuracy: 0.9209 - val_loss: 0.9038 - val_accuracy: 0.7505\n",
            "Epoch 230/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2472 - accuracy: 0.9205 - val_loss: 0.9135 - val_accuracy: 0.7442\n",
            "Epoch 231/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2346 - accuracy: 0.9239 - val_loss: 0.8751 - val_accuracy: 0.7600\n",
            "Epoch 232/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2363 - accuracy: 0.9263 - val_loss: 0.8492 - val_accuracy: 0.7596\n",
            "Epoch 233/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2394 - accuracy: 0.9246 - val_loss: 0.8830 - val_accuracy: 0.7568\n",
            "Epoch 234/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2475 - accuracy: 0.9228 - val_loss: 0.8540 - val_accuracy: 0.7549\n",
            "Epoch 235/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2427 - accuracy: 0.9235 - val_loss: 0.8626 - val_accuracy: 0.7659\n",
            "Epoch 236/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2410 - accuracy: 0.9266 - val_loss: 0.8586 - val_accuracy: 0.7560\n",
            "Epoch 237/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2406 - accuracy: 0.9239 - val_loss: 0.8920 - val_accuracy: 0.7541\n",
            "Epoch 238/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2436 - accuracy: 0.9230 - val_loss: 0.8676 - val_accuracy: 0.7580\n",
            "Epoch 239/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2380 - accuracy: 0.9236 - val_loss: 0.8953 - val_accuracy: 0.7513\n",
            "Epoch 240/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2430 - accuracy: 0.9206 - val_loss: 0.9081 - val_accuracy: 0.7473\n",
            "Epoch 241/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2493 - accuracy: 0.9208 - val_loss: 0.8850 - val_accuracy: 0.7608\n",
            "Epoch 242/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2309 - accuracy: 0.9274 - val_loss: 0.9974 - val_accuracy: 0.7422\n",
            "Epoch 243/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2488 - accuracy: 0.9219 - val_loss: 0.9327 - val_accuracy: 0.7477\n",
            "Epoch 244/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2462 - accuracy: 0.9245 - val_loss: 0.8796 - val_accuracy: 0.7537\n",
            "Epoch 245/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2458 - accuracy: 0.9230 - val_loss: 0.9030 - val_accuracy: 0.7521\n",
            "Epoch 246/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2414 - accuracy: 0.9254 - val_loss: 0.8934 - val_accuracy: 0.7489\n",
            "Epoch 247/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2332 - accuracy: 0.9267 - val_loss: 0.8690 - val_accuracy: 0.7529\n",
            "Epoch 248/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2453 - accuracy: 0.9226 - val_loss: 0.8829 - val_accuracy: 0.7576\n",
            "Epoch 249/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2514 - accuracy: 0.9192 - val_loss: 0.8669 - val_accuracy: 0.7549\n",
            "Epoch 250/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2352 - accuracy: 0.9275 - val_loss: 0.9142 - val_accuracy: 0.7422\n",
            "Epoch 251/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2394 - accuracy: 0.9255 - val_loss: 0.8795 - val_accuracy: 0.7572\n",
            "Epoch 252/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2394 - accuracy: 0.9254 - val_loss: 0.8998 - val_accuracy: 0.7632\n",
            "Epoch 253/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2325 - accuracy: 0.9277 - val_loss: 1.0115 - val_accuracy: 0.7457\n",
            "Epoch 254/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2601 - accuracy: 0.9156 - val_loss: 0.9066 - val_accuracy: 0.7560\n",
            "Epoch 255/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2365 - accuracy: 0.9268 - val_loss: 0.8991 - val_accuracy: 0.7572\n",
            "Epoch 256/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2410 - accuracy: 0.9229 - val_loss: 0.9134 - val_accuracy: 0.7513\n",
            "Epoch 257/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2303 - accuracy: 0.9272 - val_loss: 0.9838 - val_accuracy: 0.7402\n",
            "Epoch 258/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2407 - accuracy: 0.9229 - val_loss: 0.9562 - val_accuracy: 0.7465\n",
            "Epoch 259/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2378 - accuracy: 0.9267 - val_loss: 0.8819 - val_accuracy: 0.7521\n",
            "Epoch 260/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2349 - accuracy: 0.9265 - val_loss: 0.8879 - val_accuracy: 0.7600\n",
            "Epoch 261/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2494 - accuracy: 0.9232 - val_loss: 0.9123 - val_accuracy: 0.7465\n",
            "Epoch 262/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2288 - accuracy: 0.9296 - val_loss: 0.9104 - val_accuracy: 0.7525\n",
            "Epoch 263/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2465 - accuracy: 0.9226 - val_loss: 0.9061 - val_accuracy: 0.7513\n",
            "Epoch 264/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2347 - accuracy: 0.9254 - val_loss: 0.8945 - val_accuracy: 0.7525\n",
            "Epoch 265/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2363 - accuracy: 0.9267 - val_loss: 0.9073 - val_accuracy: 0.7469\n",
            "Epoch 266/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2321 - accuracy: 0.9278 - val_loss: 0.9059 - val_accuracy: 0.7549\n",
            "Epoch 267/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2331 - accuracy: 0.9286 - val_loss: 0.8863 - val_accuracy: 0.7552\n",
            "Epoch 268/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2347 - accuracy: 0.9281 - val_loss: 0.8634 - val_accuracy: 0.7588\n",
            "Epoch 269/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2321 - accuracy: 0.9271 - val_loss: 0.8948 - val_accuracy: 0.7600\n",
            "Epoch 270/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2367 - accuracy: 0.9249 - val_loss: 0.8844 - val_accuracy: 0.7632\n",
            "Epoch 271/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2439 - accuracy: 0.9261 - val_loss: 0.9424 - val_accuracy: 0.7489\n",
            "Epoch 272/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2402 - accuracy: 0.9253 - val_loss: 0.9047 - val_accuracy: 0.7525\n",
            "Epoch 273/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2315 - accuracy: 0.9267 - val_loss: 0.9150 - val_accuracy: 0.7596\n",
            "Epoch 274/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2345 - accuracy: 0.9239 - val_loss: 0.9204 - val_accuracy: 0.7430\n",
            "Epoch 275/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2404 - accuracy: 0.9261 - val_loss: 0.8965 - val_accuracy: 0.7592\n",
            "Epoch 276/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2332 - accuracy: 0.9284 - val_loss: 0.9330 - val_accuracy: 0.7493\n",
            "Epoch 277/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2379 - accuracy: 0.9280 - val_loss: 0.9325 - val_accuracy: 0.7477\n",
            "Epoch 278/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2370 - accuracy: 0.9269 - val_loss: 0.8940 - val_accuracy: 0.7588\n",
            "Epoch 279/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2327 - accuracy: 0.9280 - val_loss: 0.9485 - val_accuracy: 0.7572\n",
            "Epoch 280/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2417 - accuracy: 0.9253 - val_loss: 0.9180 - val_accuracy: 0.7564\n",
            "Epoch 281/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2361 - accuracy: 0.9280 - val_loss: 0.8798 - val_accuracy: 0.7545\n",
            "Epoch 282/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2235 - accuracy: 0.9286 - val_loss: 0.9337 - val_accuracy: 0.7461\n",
            "Epoch 283/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2314 - accuracy: 0.9282 - val_loss: 0.9441 - val_accuracy: 0.7386\n",
            "Epoch 284/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2430 - accuracy: 0.9253 - val_loss: 0.9854 - val_accuracy: 0.7469\n",
            "Epoch 285/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2266 - accuracy: 0.9282 - val_loss: 0.9317 - val_accuracy: 0.7493\n",
            "Epoch 286/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2323 - accuracy: 0.9297 - val_loss: 0.8862 - val_accuracy: 0.7584\n",
            "Epoch 287/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2366 - accuracy: 0.9277 - val_loss: 0.9430 - val_accuracy: 0.7509\n",
            "Epoch 288/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2308 - accuracy: 0.9290 - val_loss: 0.9007 - val_accuracy: 0.7497\n",
            "Epoch 289/300\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.2329 - accuracy: 0.9277 - val_loss: 0.8885 - val_accuracy: 0.7556\n",
            "Epoch 290/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2347 - accuracy: 0.9266 - val_loss: 0.9017 - val_accuracy: 0.7632\n",
            "Epoch 291/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2414 - accuracy: 0.9261 - val_loss: 0.8373 - val_accuracy: 0.7628\n",
            "Epoch 292/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2300 - accuracy: 0.9277 - val_loss: 0.9577 - val_accuracy: 0.7493\n",
            "Epoch 293/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2339 - accuracy: 0.9279 - val_loss: 0.9100 - val_accuracy: 0.7556\n",
            "Epoch 294/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2280 - accuracy: 0.9299 - val_loss: 0.9113 - val_accuracy: 0.7600\n",
            "Epoch 295/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2299 - accuracy: 0.9292 - val_loss: 0.9181 - val_accuracy: 0.7525\n",
            "Epoch 296/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2401 - accuracy: 0.9272 - val_loss: 0.8563 - val_accuracy: 0.7600\n",
            "Epoch 297/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2297 - accuracy: 0.9299 - val_loss: 0.9029 - val_accuracy: 0.7636\n",
            "Epoch 298/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2351 - accuracy: 0.9290 - val_loss: 0.9526 - val_accuracy: 0.7541\n",
            "Epoch 299/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2402 - accuracy: 0.9253 - val_loss: 0.8703 - val_accuracy: 0.7624\n",
            "Epoch 300/300\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2452 - accuracy: 0.9247 - val_loss: 0.8278 - val_accuracy: 0.7545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhpP7M24T9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8965af-43b6-4006-df13-8b783867d33b"
      },
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 9ms/step - loss: 0.8278 - accuracy: 0.7545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjw94aij4T-C"
      },
      "source": [
        "# perform pruning here\n",
        "\n",
        "# get the weights \n",
        "weights = model.get_weights()\n",
        "\n",
        "# you can use set_weights() to set some weights to zero, e.g.,\n",
        "# some references for pruning techniques: https://arxiv.org/pdf/1810.05270v2.pdf, https://arxiv.org/pdf/2001.04062.pdf\n",
        "\n",
        "# weights[7][:10]=0\n",
        "model.set_weights(weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUuNXFjV4T-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168e2d73-9360-4fbd-a532-ca702243756d"
      },
      "source": [
        "# evaluate again to see how the accuracy changes\n",
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 7ms/step - loss: 1.0858 - accuracy: 0.5564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMSKQW4k4T-G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "54fb3ac0-a007-4741-f2eb-6324077c3c27"
      },
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model.save_weights(\"uncompressed_model_weights.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "files.download(\"uncompressed_model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_30c3102e-cc91-4743-ad41-99de68a5adfa\", \"uncompressed_model_weights.h5\", 2407560)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}